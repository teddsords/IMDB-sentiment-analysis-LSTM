{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with IMDB movie reviews\n",
    "\n",
    "In this notebook we will perform sentimend analysis for IMDB movie reviews. This dataset was downloaded from Kaggle, you can download it too in the following link: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews. There are 50k movie revies within the dataset, all of them are labeled. Those labels have values of: negative and positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\teddy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data & Pre-processing data\n",
    "\n",
    "As you can see, there are 50k lines and two columns. The sentiment column is our output. This dataset needs some processing because there are special characters and HTML tags within the review, so we will be performing a quick cleaning process before continuing our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Data:\n",
      " 0        one reviewers mentioned watching oz episode ho...\n",
      "1        a wonderful little production the filming tech...\n",
      "2        i thought wonderful way spend time hot summer ...\n",
      "3        basically family little boy jake thinks zombie...\n",
      "4        petter mattei love time money visually stunnin...\n",
      "                               ...                        \n",
      "49995    i thought movie right good job it creative ori...\n",
      "49996    bad plot bad dialogue bad acting idiotic direc...\n",
      "49997    i catholic taught parochial elementary schools...\n",
      "49998    i going disagree previous comment side maltin ...\n",
      "49999    no one expects star trek movies high art fans ...\n",
      "Name: review, Length: 50000, dtype: object\n",
      "Y Data:\n",
      " 0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "49995    1\n",
      "49996    0\n",
      "49997    0\n",
      "49998    0\n",
      "49999    0\n",
      "Name: sentiment, Length: 50000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separating data into independent and dependent variables\n",
    "x_data = df['review']\n",
    "y_data = df['sentiment']\n",
    "\n",
    "# Cleaning X data\n",
    "stop_words = set(stopwords.words('english'))    # Getting english stop words to concentrate in the important information\n",
    "x_data = x_data.replace({'<.*?>': ''}, regex= True) # Removing All the HTML tags\n",
    "x_data = x_data.replace({'[^A-Za-z]': ' '}, regex= True) # Removing everything that doesn't belong to the alphabet\n",
    "x_data = x_data.apply(lambda review: [w for w in review.split() if w not in stop_words])    # Removing stop words from the reviews\n",
    "x_data = x_data.apply(lambda review: \" \".join([w.lower() for w in review]))   # Lowercasing all words in the review\n",
    "\n",
    "# Transformating Y data\n",
    "y_data = y_data.replace('positive', 1)  # 1 represents positive reviews and 0 represents negative reviews in newer label\n",
    "y_data = y_data.replace('negative', 0)\n",
    "\n",
    "# Showing transformed data\n",
    "print('X Data:\\n', x_data)\n",
    "print('Y Data:\\n', y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split\n",
    "\n",
    "We need to split the data into training and testing data, for this we will be using the method provided by scikitlearn. We will be using 30% for test and the remaining 70% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000,), (35000,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=123, stratify=y_data)\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the median length for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_length = []\n",
    "for review in x_train:\n",
    "    review_length.append(len(review))\n",
    "\n",
    "median_length = int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[  320     5  7607 ...     0     0     0]\n",
      " [ 2240  2736   202 ...     0     0     0]\n",
      " [    7    94  2200 ...     0     0     0]\n",
      " ...\n",
      " [ 1811 14915     2 ...     0     0     0]\n",
      " [    2    13   255 ...     0     0     0]\n",
      " [ 1306  6441   149 ...   162   539   330]] \n",
      "\n",
      "Encoded X Test\n",
      " [[  868  3516  1310 ...  2752   266 42604]\n",
      " [  106  1558  6561 ...     0     0     0]\n",
      " [  680 15392    78 ...     0     0     0]\n",
      " ...\n",
      " [  106     1  1720 ...   412  1261  4410]\n",
      " [    8  3054   830 ...  2188  2215   418]\n",
      " [ 2848   392    18 ...     0     0     0]] \n",
      "\n",
      "Maximum review length:  130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35000, 130)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = median_length \n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "Our model will have a **embedding layer**, **LSTM layer** and a **Dense layer**. The embedded layer will have a size of **16** and LSTM wil have a size of **32**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 130, 16)           1399408   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                6272      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,405,713\n",
      "Trainable params: 1,405,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedded_size = 16\n",
    "lstm_size = 32\n",
    "word_size = len(token.word_index) + 1       # +1 due to padding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_size, embedded_size, input_length = median_length))\n",
    "model.add(LSTM(lstm_size))\n",
    "model.add(Dense(1, activation= 'sigmoid'))\n",
    "model.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model\n",
    "\n",
    "We need to fit the model with out training data. For this training session we will be using mini batch, with a size of 128 and 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath= 'models/LSTM.h5', monitor= 'accuracy', save_best_only= True, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 130) (35000,)\n",
      "Epoch 1/5\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.6712\n",
      "Epoch 1: accuracy improved from -inf to 0.67117, saving model to models\\LSTM.h5\n",
      "274/274 [==============================] - 33s 100ms/step - loss: 0.5726 - accuracy: 0.6712\n",
      "Epoch 2/5\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.9031\n",
      "Epoch 2: accuracy improved from 0.67117 to 0.90311, saving model to models\\LSTM.h5\n",
      "274/274 [==============================] - 27s 99ms/step - loss: 0.2555 - accuracy: 0.9031\n",
      "Epoch 3/5\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9567\n",
      "Epoch 3: accuracy improved from 0.90311 to 0.95666, saving model to models\\LSTM.h5\n",
      "274/274 [==============================] - 28s 103ms/step - loss: 0.1362 - accuracy: 0.9567\n",
      "Epoch 4/5\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9761\n",
      "Epoch 4: accuracy improved from 0.95666 to 0.97606, saving model to models\\LSTM.h5\n",
      "274/274 [==============================] - 28s 101ms/step - loss: 0.0869 - accuracy: 0.9761\n",
      "Epoch 5/5\n",
      "274/274 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9859\n",
      "Epoch 5: accuracy improved from 0.97606 to 0.98594, saving model to models\\LSTM.h5\n",
      "274/274 [==============================] - 28s 102ms/step - loss: 0.0574 - accuracy: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e11ec7130>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size= 128, epochs= 5, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "We need to evaluate the model's performance on unseen data and comparing it to the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 8s 18ms/step\n",
      "Accuracy: 86.66\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(x_test) > 0.5).astype('int32')\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y == y_pred[i]:\n",
    "        true+=1\n",
    "\n",
    "accuracy = (true/len(y_pred)) * 100\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d30d0fbf74c167e6f35cdec0b33a93935075f1d86b5335053160b1f0e52b85f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
